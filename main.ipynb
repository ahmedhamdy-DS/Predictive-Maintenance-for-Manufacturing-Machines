{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba81611",
   "metadata": {},
   "source": [
    "#  Predictive Maintenance for Manufacturing Machines\n",
    "\n",
    "!<img src=\"assets/images.jpeg\" alt=\"Workflow\" width=\"500\">\n",
    "\n",
    "**Problem:** Unexpected machine failures lead to downtime and high costs.\n",
    "\n",
    "**Goal:** Predict machine failures and generate actionable Failure Scheduling Reports to prevent them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6abbb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Overview:** Utilizing sensor data and implementing an ML pipeline to build a model that predicts mechanical failures before they occur.\n",
    "\n",
    "* **Estimated time:** 45 minutes\n",
    "* **Difficulty:** Intermediate\n",
    "\n",
    "---\n",
    "\n",
    "##  Operational Environment & Objective\n",
    "(Visuals of Equipment / Data)\n",
    "\n",
    "This project aims to analyze real-time operational data from a set of industrial machines. By monitoring key variables such as temperature, vibration, and rotational speed, we can identify patterns that precede mechanical failure.\n",
    "\n",
    "**Core Objective:** To transition from reactive maintenance (repair after failure) to predictive maintenance (repair before failure).\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "##  The Problem: Cost of Unplanned Downtime\n",
    "(Problem Statement)\n",
    "\n",
    "Unplanned machine downtime is incredibly costly, leading to lost production and increased emergency repair expenses. This project directly addresses this issue.\n",
    "\n",
    "| Normal Operation | Failure State |\n",
    "| :---: | :---: |\n",
    "|  |  |\n",
    "| The motor operates efficiently within normal temperature and vibration ranges. | A sudden temperature spike and evident wear led to machine failure. |\n",
    "\n",
    "---\n",
    "\n",
    "##  Data Table Preview\n",
    "(Data Table Preview)\n",
    "\n",
    "Our dataset comprises multiple sensor readings collected over time, along with a target variable indicating whether a failure occurred.\n",
    "\n",
    "**Sample Sensor Data:**\n",
    "\n",
    "| Machine ID | Temp (K) | Torque (Nm) | Rotational Speed (rpm) | Failure? |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| M14860 | 302.6 | 60.1 | 1625 | 0 |\n",
    "| M14861 | 302.7 | 42.8 | 1410 | 0 |\n",
    "| M14862 | 301.9 | 47.6 | 1782 | 1 (TWF) |\n",
    "| M14863 | 302.4 | 47.9 | 1667 | 0 |\n",
    "| M14864 | 302.5 | 40.2 | 1768 | 0 |\n",
    "\n",
    "> **Note:** `Failure? = 0` means normal operation, while `Failure? = 1` indicates an error. (TWF = Tool Wear Failure).\n",
    "\n",
    "---\n",
    "\n",
    "## Project Roadmap\n",
    "(Workflow Diagram)\n",
    "\n",
    "To achieve our goal, we will follow a standard data science workflow:\n",
    "\n",
    "\n",
    "\n",
    "1.  **Data Collection:** Loading sensor data.\n",
    "2.  **Preprocessing:** Handling missing data and feature engineering.\n",
    "3.  **Modeling:** Training various models (e.g., Random Forest, XGBoost) to detect failures.\n",
    "4.  **Evaluation:** Measuring model accuracy and predictive capability.\n",
    "5.  **Predictions:** Using the model to forecast future maintenance schedules.\n",
    "\n",
    "---\n",
    "\n",
    "##  Let's Start Implementing\n",
    "(Interactive Notes & Structure)\n",
    "\n",
    "Now, let's dive into the code. The notebook is structured into the following sections for easy navigation:\n",
    "\n",
    "1.  **[1]  Importing Libraries & Loading Data**\n",
    "2.  **[2]  Exploratory Data Analysis (EDA)**\n",
    "3.  **[3]  Feature Engineering & Preprocessing**\n",
    "4.  **[4]  Training & Evaluating the Machine Learning Model**\n",
    "5.  **[5]  Interpreting Results & Final Conclusion**\n",
    "\n",
    "---\n",
    "*(... code starts here ...)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1bf12",
   "metadata": {},
   "source": [
    "## Part 1: Obtaining the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f728d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Standard Libraries ==========\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# ========== Scikit-learn ==========\n",
    "from sklearn.model_selection import train_test_split, learning_curve, validation_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Metrics & Evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    mean_squared_error,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_auc_score,\n",
    "    classification_report\n",
    "\n",
    ")\n",
    "\n",
    "# ========== Imbalanced Data ==========\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ========== XGBoost ==========\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ========== Save Model==========\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8a8f3",
   "metadata": {},
   "source": [
    "## Part 2: Scrubbing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b62e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"predictive_maintenance.csv\")\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab11d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e38fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34992d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023576e4",
   "metadata": {},
   "source": [
    "## Part 3: Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86123a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#===========================================================\n",
    "# 1) TARGET DISTRIBUTION (Interactive Donut Chart)\n",
    "#===========================================================\n",
    "\n",
    "fig_target = px.pie(\n",
    "    df,\n",
    "    names=\"Target\",\n",
    "    hole=0.5,\n",
    "    color=\"Target\",\n",
    "    color_discrete_map={0:\"#1f77b4\", 1:\"#d62728\"},\n",
    "    title=\"Failure vs Normal Distribution\"\n",
    ")\n",
    "fig_target.update_layout(width=500, height=400)\n",
    "fig_target.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5010bb0",
   "metadata": {},
   "source": [
    "ðŸ’¡ **Practical Insight**  \n",
    "This chart is a classic example of visualizing the **target variable** in a **binary classification problem**.\n",
    "\n",
    "**Business Context:**  \n",
    "The title **\"Failure vs Normal Distribution\"** strongly suggests that this dataset is used to **predict failures**.  \n",
    "\n",
    "- **0 (Blue)** â†’ \"Normal\" or Negative class  \n",
    "- **1 (Red)** â†’ \"Failure\" or Positive class (the event we want to predict)  \n",
    "\n",
    "**Key Insight:**  \n",
    "The chart shows **96.6% Normal vs 3.39% Failure**, which immediately reveals that the dataset is **highly imbalanced**. The \"Failure\" class is a **rare event**.\n",
    "\n",
    "**Why this matters:**  \n",
    "When training a machine learning model, this imbalance is critical. A naive model could achieve **96.6% accuracy** simply by predicting \"Normal\" every time, **failing completely to detect failures**.  \n",
    "\n",
    "This chart is an essential first step, alerting the data scientist to apply **special techniques** such as:  \n",
    "- **Oversampling / Undersampling**  \n",
    "- **SMOTE or ADASYN**  \n",
    "- Using appropriate evaluation metrics like **F1-Score**, **Precision-Recall AUC**, or **Balanced Accuracy**  \n",
    "\n",
    "These approaches help in building a model that can **effectively detect rare failure events**, not just the majority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04982331",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the visual theme for all plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- 1. Understand Your Target: Failure & Imbalance ---\n",
    "print(\"\\n--- Generating Plot 1: Target Variable Analysis ---\")\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Target (Failure vs. No Failure)\n",
    "plt.subplot(1, 2, 1)\n",
    "ax1 = sns.countplot(data=df, x='Target')\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.xlabel('Target (0 = No Failure, 1 = Failure)')\n",
    "plt.ylabel('Count')\n",
    "# Add count labels\n",
    "for p in ax1.patches:\n",
    "    ax1.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', xytext=(0, 5), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca743e",
   "metadata": {},
   "source": [
    "ðŸ’¡ **Practical Insight**  \n",
    "This bar chart provides the **same insight** as the donut chart, but in a **more direct way**.\n",
    "\n",
    "**Key Insight:**  \n",
    "The chart highlights the **severe class imbalance** in the dataset:\n",
    "\n",
    "- **0 (No Failure) â†’ Blue:** 9661 instances  \n",
    "- **1 (Failure) â†’ Red:** 339 instances  \n",
    "\n",
    "**Why this chart is useful:**  \n",
    "- The **height of the bars** gives an immediate sense of quantity.  \n",
    "- Exact counts are **annotated on top of the bars**, making the imbalance unmistakably clear.  \n",
    "- No need to hover or read the y-axisâ€”the difference is obvious at a glance.\n",
    "\n",
    "**Context:**  \n",
    "The command `plt.subplot(1, 2, 1)` suggests this is **part 1 of a two-part visualization**, likely paired with a donut chart or another plot to explore the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f8d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot 2: Failure Type (for failures only)\n",
    "plt.subplot(1, 2, 2)\n",
    "# We only want to plot actual failures, not the 'No Failure' category\n",
    "failure_data = df[df['Target'] == 1]\n",
    "ax2 = sns.countplot(data=failure_data, x='Failure Type')\n",
    "plt.title('Failure Type Distribution (when Target == 1)')\n",
    "plt.xlabel('Failure Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=30)\n",
    "# Add count labels\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9872b1",
   "metadata": {},
   "source": [
    "ðŸ’¡ **Practical Insight**  \n",
    "This chart is an excellent example of a **drill-down analysis**.\n",
    "\n",
    "**Context:**  \n",
    "The first plot showed that **failures were occurring (339 instances)**.  \n",
    "This second plot answers the next logical question:  \n",
    "> \"What kind of failures are they?\"\n",
    "\n",
    "**Key Insight:**  \n",
    "By filtering for `Target == 1`, this chart breaks down the **339 failure cases** into their specific **root causes**.  \n",
    "\n",
    "- **Heat Dissipation Failure:** 112 instances (most frequent)  \n",
    "- **Power Failure:** 95 instances (second most common)  \n",
    "- **No Failure:** 9 instances (interesting, possibly a **data entry error** or a flagged failure without a specific type)  \n",
    "\n",
    "**Business Value:**  \n",
    "This analysis is highly actionable. Instead of just knowing that there are **339 failures**, a maintenance or engineering team can now focus efforts where it matters most:  \n",
    "\n",
    "> \"Focus on fixing heat dissipation and power supply issues,\"  \n",
    "\n",
    "which would address **207 out of 339 failures (~61%)**, significantly improving efficiency and impact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f71d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. Analyze Sensor & Process Distributions ---\n",
    "print(\"\\n--- Generating Plot 2: Sensor & Process Distributions ---\")\n",
    "numerical_features = [\n",
    "    'Air temperature [K]', \n",
    "    'Process temperature [K]', \n",
    "    'Rotational speed [rpm]', \n",
    "    'Torque [Nm]', \n",
    "    'Tool wear [min]'\n",
    "]\n",
    "\n",
    "# Create a figure with subplots (2 columns)\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.suptitle('Sensor & Process Feature Distributions', fontsize=16, y=1.02)\n",
    "\n",
    "for i, col in enumerate(numerical_features):\n",
    "    # Plot 1: Histogram (Distribution)\n",
    "    plt.subplot(len(numerical_features), 2, 2*i + 1)\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    \n",
    "    # Plot 2: Box Plot (Outliers)\n",
    "    plt.subplot(len(numerical_features), 2, 2*i + 2)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 1]) # Adjust layout to prevent suptitle overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ffca04",
   "metadata": {},
   "source": [
    "ðŸ’¡ **Practical Insight**  \n",
    "This is a **fundamental step** in Exploratory Data Analysis (EDA).  \n",
    "The goal is to **understand the dataset's features** before using them for machine learning. This visual **dashboard** is extremely valuable.\n",
    "\n",
    "**Complementary Views:**  \n",
    "The code cleverly plots **two different charts for each feature**:\n",
    "\n",
    "- **Histogram (Left):**  \n",
    "  Shows the **shape of the distribution**.  \n",
    "  - `'Air temperature'`, `'Process temperature'`, `'Rotational speed'` â†’ roughly **normal (bell curve)**  \n",
    "  - `'Torque'` and `'Tool wear'` â†’ **non-normal shapes**, slightly skewed\n",
    "\n",
    "- **Box Plot (Right):**  \n",
    "  Shows the **summary and outliers**.  \n",
    "  - The **box** represents the **middle 50%** of the data  \n",
    "  - The **whiskers** show the rest of the data  \n",
    "  - Individual dots (e.g., in `'Rotational speed [rpm]'` and `'Torque [Nm]'`) are **outliers**â€”points that are statistically far from the rest  \n",
    "\n",
    "**Key Business Finding:**  \n",
    "The most immediate observation is the presence of **significant outliers** in `'Rotational speed'` and `'Torque'`.  \n",
    "A data scientist must investigate whether these are:\n",
    "\n",
    "1. **Real events** (e.g., a machine spinning too fast or a sudden spike in torque) that might **predict failure**, or  \n",
    "2. **Sensor errors / bad data** that should be **cleaned or removed**  \n",
    "\n",
    "This analysis is **critical** for:  \n",
    "- **Data cleaning**  \n",
    "- Deciding how to **scale or normalize** these features before feeding them into a predictive model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1cb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Find Relationships ---\n",
    "\n",
    "# 3a. Correlation Heatmap\n",
    "print(\"\\n--- Generating Plot 3a: Correlation Heatmap ---\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Select only numerical columns for correlation\n",
    "corr_df = df[numerical_features + ['Target']]\n",
    "corr = corr_df.corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3248f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3b. Feature vs. Failure (Box Plots)\n",
    "print(\"\\n--- Generating Plot 3b: Feature vs. Failure (Box Plots) ---\")\n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.suptitle('Numerical Features vs. Failure (Target)', fontsize=16, y=1.02)\n",
    "for i, col in enumerate(numerical_features):\n",
    "    plt.subplot(2, 3, i + 1) # Arrange in a 2x3 grid\n",
    "    sns.boxplot(data=df, x='Target', y=col)\n",
    "    plt.title(f'{col}')\n",
    "    plt.xlabel('Target (0 = No Failure, 1 = Failure)')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4190b",
   "metadata": {},
   "source": [
    "ðŸ’¡ **Practical Insight**  \n",
    "This is one of the **most powerful and common visualizations** in predictive maintenance.  \n",
    "It directly answers the question:  \n",
    "> \"Do my sensor readings look different right before a failure?\"\n",
    "\n",
    "**How to read it:**  \n",
    "By comparing the **\"0\" (No Failure)** box with the **\"1\" (Failure)** box for each feature, we can identify signals that predict a problem.\n",
    "\n",
    "**Strongest Predictor:**  \n",
    "- **Tool wear [min]:** The \"Failure\" (1) box is almost entirely **above** the \"No Failure\" (0) box.  \n",
    "  - Failures almost always occur when **tool wear is high** (e.g., > 200 min).\n",
    "\n",
    "**Strong Predictors:**  \n",
    "- **Torque [Nm]:** Failures (1) are clearly associated with **higher torque** values.  \n",
    "- **Rotational speed [rpm]:** Failures (1) are associated with **lower rotational speeds**.\n",
    "\n",
    "**Weaker Predictors:**  \n",
    "- **Air temperature [K]** and **Process temperature [K]:** Failures (1) tend to occur at **slightly higher temperatures**, but there is significant **overlap** with the \"No Failure\" (0) boxes, making them less reliable individually.\n",
    "\n",
    "**Business Value:**  \n",
    "This chart enables a shift from **reactive maintenance to predictive maintenance**.  \n",
    "- A machine learning model could **learn these patterns**.  \n",
    "- Even without a model, engineers could set up a simple alert:  \n",
    "> \"If tool wear > 200 min **AND** torque > 60 Nm **AND** rotational speed < 1400 rpm, flag the machine for inspection.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3c. Torque vs. Rotational Speed (Scatter Plot)\n",
    "print(\"\\n--- Generating Plot 3c: Torque vs. Rotational Speed ---\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Use a subset if the dataset is huge, but 10,000 is fine\n",
    "sns.scatterplot(\n",
    "    data=df.sample(n=min(5000, len(df))), # Sample to avoid overplotting if N is very large\n",
    "    x='Rotational speed [rpm]', \n",
    "    y='Torque [Nm]', \n",
    "    hue='Target', \n",
    "    palette={0: '#0072B2', 1: '#D55E00'}, # Color-blind friendly\n",
    "    alpha=0.5,\n",
    "    style='Target'\n",
    ")\n",
    "plt.title('Torque vs. Rotational Speed (Colored by Failure)')\n",
    "plt.legend(title='Target', labels=['1 - Failure', '0 - No Failure'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6903790",
   "metadata": {},
   "source": [
    "ðŸ’¡ **Practical Insight**  \n",
    "This plot provides a **\"map\" of the machine's operating behavior** and its **\"danger zones.\"**\n",
    "\n",
    "**Main Relationship:**  \n",
    "- There is a **strong negative correlation** between speed and torque.  \n",
    "- As **speed increases**, **torque decreases**.  \n",
    "- This is typical for many motors (**Power â‰ˆ Torque Ã— Speed**).  \n",
    "  - For relatively constant power, if one goes up, the other must come down.\n",
    "\n",
    "**Key Finding (Failure Clusters):**  \n",
    "The failures (orange 'x's) are **not random**; they are concentrated in **two distinct regions**:\n",
    "\n",
    "1. **Low Speed / High Torque:**  \n",
    "   - Cluster in top-left (**speed < 1750, torque > 40**)  \n",
    "   - Represents a **\"high-strain\" / \"lugging\"** condition\n",
    "\n",
    "2. **High Speed / Low Torque:**  \n",
    "   - Cluster in bottom-right (**speed > 2250, torque < 20**)  \n",
    "   - Represents a **\"high-spin\" / \"low-load\"** condition\n",
    "\n",
    "**Business Value:**  \n",
    "- Failure is not simply \"too much torque\" or \"too much speed.\"  \n",
    "- It's the **combination of variables** that predicts failure.  \n",
    "- This plot **defines the safe operating envelope** (dense blue area) and highlights **high-risk \"danger zones\"**.  \n",
    "- A **predictive maintenance model** could learn to flag these zones to prevent failures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19901072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 4. Analyze Categorical Data (Product Type) ---\n",
    "print(\"\\n--- Generating Plot 4: Categorical Data Analysis ---\")\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Absolute Counts\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(data=df, x='Type', hue='Target', order=['L', 'M', 'H'])\n",
    "plt.title('Failure Counts by Product Type')\n",
    "plt.legend(title='Target', labels=['0 - No Failure', '1 - Failure'])\n",
    "\n",
    "# Plot 2: Normalized (Failure Rate)\n",
    "plt.subplot(1, 2, 2)\n",
    "# Calculate failure rate per type\n",
    "failure_rate = df.groupby('Type')['Target'].mean().reset_index()\n",
    "sns.barplot(data=failure_rate, x='Type', y='Target', order=['L', 'M', 'H'], palette='viridis')\n",
    "plt.title('Average Failure Rate by Product Type')\n",
    "plt.ylabel('Failure Rate (Proportion)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a52b6e",
   "metadata": {},
   "source": [
    "ðŸ’¡ **Practical Insight**  \n",
    "This is a **perfect example of why normalization is critical**.\n",
    "\n",
    "**Plot 1 (Absolute Counts):**  \n",
    "- Misleading at first glance.  \n",
    "- Shows that **\"L\" (Low) type products** have the most failures (orange bar is tallest).  \n",
    "- A manager might wrongly conclude:  \n",
    "> \"L type products are the biggest problem.\"  \n",
    "- The reason the bar is tallest is simply that **\"L\" is the most common product type** in the dataset (blue bar is also tallest).\n",
    "\n",
    "**Plot 2 (Failure Rate):**  \n",
    "- Tells the **real story**.  \n",
    "- Answers the question:  \n",
    "> \"Given a product of type L, M, or H, what is its probability of failing?\"  \n",
    "- Shows that **\"L\" type products have the highest failure rate (~3.9%)**, while **\"H\" type products**, despite having some failures, are actually the **most reliable**.\n",
    "\n",
    "**Business Value:**  \n",
    "This analysis correctly identifies that the **\"L\" product line is proportionally the least reliable**, even though it is the most common.  \n",
    "- Guides the engineering team to **investigate why L type fails more often**, rather than just focusing on it due to total failure counts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4a028",
   "metadata": {},
   "source": [
    "## 4. Modeling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3060d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "numeric_cols = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]',\n",
    "                'Torque [Nm]', 'Tool wear [min]']\n",
    "\n",
    "z_scores = np.abs(stats.zscore(df[numeric_cols]))\n",
    "\n",
    "outliers = df[(z_scores > 3).any(axis=1)]\n",
    "\n",
    "print(outliers.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12959da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop([\"UDI\",\"Product ID\"] , axis=1)\n",
    "dummies = pd.get_dummies(df[\"Failure Type\"], drop_first=True)\n",
    "df = pd.concat([df.drop(\"Failure Type\", axis=1), dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28102433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, f1_score, \n",
    "    precision_score, recall_score, roc_curve\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,\n",
    "    ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# --- Configuration & Setup ---\n",
    "\n",
    "# !! ASSUMPTION: 'df' is already loaded as a pandas DataFrame\n",
    "# Example:\n",
    "# df = pd.read_csv('your_data.csv') \n",
    "\n",
    "# numeric & categorical\n",
    "num_cols = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]',\n",
    "            \"Torque [Nm]\", \"Tool wear [min]\"]\n",
    "categ_cols = ['Type']\n",
    "\n",
    "\n",
    "# --- Preprocessing Pipeline ---\n",
    "\n",
    "# ColumnTransformer\n",
    "all_pipeline = ColumnTransformer(transformers=[\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), num_cols),\n",
    "\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "    ]), categ_cols),\n",
    "], remainder='drop') \n",
    "\n",
    "\n",
    "# --- Data Splitting ---\n",
    "try:\n",
    "    y = df[\"Target\"]\n",
    "    x = df.drop([\"Target\"], axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # --- Apply Preprocessing ---\n",
    "    X_train_final = all_pipeline.fit_transform(X_train)\n",
    "    X_test_final = all_pipeline.transform(X_test)\n",
    "\n",
    "    print(f\"Training data shape: {X_train_final.shape}\")\n",
    "    print(f\"Test data shape: {X_test_final.shape}\")\n",
    "\n",
    "    # ============================\n",
    "    #  Dynamic Class Weight Calculation\n",
    "    # ============================\n",
    "    try:\n",
    "        counts = np.bincount(y_train)\n",
    "        scale_pos_weight = counts[0] / counts[1]\n",
    "        print(f\"Calculated scale_pos_weight for imbalance: {scale_pos_weight:.2f}\")\n",
    "    except (IndexError, ZeroDivisionError) as e:\n",
    "        print(f\"Warning: Could not calculate scale_pos_weight ({e}). Defaulting to 1.\")\n",
    "        scale_pos_weight = 1\n",
    "        \n",
    "\n",
    "    # ============================\n",
    "    #  MODELS LIST\n",
    "    # ============================\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(\n",
    "            max_iter=500, class_weight=\"balanced\", random_state=42),\n",
    "\n",
    "        \"RandomForest\": RandomForestClassifier(\n",
    "            n_estimators=200, random_state=42, class_weight=\"balanced\"),\n",
    "\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(\n",
    "            n_estimators=300, random_state=42, class_weight=\"balanced\"),\n",
    "        \n",
    "        \"GradientBoosting\": GradientBoostingClassifier(\n",
    "            random_state=42), \n",
    "\n",
    "        \"AdaBoost\": AdaBoostClassifier(\n",
    "            n_estimators=200, random_state=42), \n",
    "\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            eval_metric=\"logloss\", random_state=42,\n",
    "            scale_pos_weight=scale_pos_weight), \n",
    "\n",
    "        \"LightGBM\": LGBMClassifier(\n",
    "            class_weight='balanced', random_state=42, verbose=-1), \n",
    "\n",
    "        \"CatBoost\": CatBoostClassifier(\n",
    "            iterations=1000, \n",
    "            depth=8,\n",
    "            learning_rate=0.03,\n",
    "            l2_leaf_reg=5,\n",
    "            loss_function='Logloss',\n",
    "            eval_metric='AUC',\n",
    "            scale_pos_weight=scale_pos_weight, \n",
    "            random_state=42,\n",
    "            verbose=0\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "    # ============================\n",
    "    #  Train & Evaluation\n",
    "    # ============================\n",
    "    \n",
    "    # List to store results for DataFrame\n",
    "    results_list = []\n",
    "    \n",
    "    # List to store data for ROC plot\n",
    "    roc_plot_data = []\n",
    "\n",
    "    print(\"\\n--- Starting Model Training & Evaluation ---\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Fitting {name}...\")\n",
    "        try:\n",
    "            # Train model\n",
    "            model.fit(X_train_final, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test_final)\n",
    "            y_pred_proba = model.predict_proba(X_test_final)[:, 1] # Proba for class 1\n",
    "\n",
    "            # Get metrics\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            \n",
    "            # Store results for DataFrame\n",
    "            results_list.append({\n",
    "                \"Model\": name,\n",
    "                \"AUC\": auc,\n",
    "                \"F1 (Macro)\": f1,\n",
    "                \"Recall (Macro)\": recall,\n",
    "                \"Precision (Macro)\": precision\n",
    "            })\n",
    "            \n",
    "            # NEW: Store data for ROC Plot\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "            roc_plot_data.append({\n",
    "                'name': name,\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr,\n",
    "                'auc': auc\n",
    "            })\n",
    "\n",
    "            # Print classification report\n",
    "            print(f\"\\n====== {name} Report ======\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            print(f\"AUC: {auc:.4f}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n!!!!!! FAILED to train or evaluate {name} !!!!!!\")\n",
    "            print(f\"Error: {e}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    # ============================\n",
    "    #  Final Summary Report (Table)\n",
    "    # ============================\n",
    "    results_df = pd.DataFrame() # Initialize empty\n",
    "    if results_list:\n",
    "        print(\"\\n\\n--- Model Performance Summary ---\")\n",
    "        results_df = pd.DataFrame(results_list)\n",
    "        results_df_sorted = results_df.sort_values(by=\"AUC\", ascending=False)\n",
    "        print(results_df_sorted.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No models were successfully trained.\")\n",
    "\n",
    "    \n",
    "    # ======================================================\n",
    "    #  NEW: ðŸ“ˆ Model Visualization\n",
    "    # ======================================================\n",
    "    \n",
    "    if not results_df.empty:\n",
    "        \n",
    "        # --- Plot 1: ROC-AUC Curves ---\n",
    "        print(\"\\nGenerating ROC-AUC Curves Plot...\")\n",
    "        plt.figure(figsize=(12, 9))\n",
    "        \n",
    "        # Plot the \"chance\" line\n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='Chance (AUC = 0.50)')\n",
    "        \n",
    "        # Plot each model's ROC curve\n",
    "        for item in roc_plot_data:\n",
    "            plt.plot(item['fpr'], item['tpr'], \n",
    "                     label=f\"{item['name']} (AUC = {item['auc']:.4f})\")\n",
    "        \n",
    "        plt.xlabel('False Positive Rate (FPR)')\n",
    "        plt.ylabel('True Positive Rate (TPR)')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curves', fontsize=16)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # --- Plot 2: Performance Metrics Comparison (Bar Charts) ---\n",
    "        print(\"Generating Performance Metrics Comparison Plot...\")\n",
    "        \n",
    "        # Melt the DataFrame to long format for easier plotting with Seaborn\n",
    "        df_melted = results_df.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "        \n",
    "        # Create a grid of bar plots (FacetGrid)\n",
    "        g = sns.catplot(\n",
    "            data=df_melted,\n",
    "            x='Score',\n",
    "            y='Model',\n",
    "            col='Metric',\n",
    "            kind='bar',\n",
    "            col_wrap=2,       # Wrap after 2 columns\n",
    "            height=5,\n",
    "            aspect=1.2,\n",
    "            sharex=False,     # Each plot has its own x-axis scale\n",
    "            palette='viridis'\n",
    "        )\n",
    "        \n",
    "        # Set titles and layout\n",
    "        g.set_titles(\"{col_name}\", size=14)\n",
    "        g.fig.suptitle('Model Performance Metrics Comparison', y=1.03, size=18)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"\\nSkipping visualization as no models were successfully trained.\")\n",
    "\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nError: The DataFrame 'df' is not defined.\")\n",
    "    print(\"Please load your data into a DataFrame named 'df' before running this script.\")\n",
    "except KeyError as e:\n",
    "    print(f\"\\nError: A required column {e} was not found in the DataFrame.\")\n",
    "    print(\"Please check your column names ('Target', num_cols, categ_cols).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c2e54",
   "metadata": {},
   "source": [
    "ðŸ’¡ **Practical Insight â€“ Model Training & Evaluation**  \n",
    "\n",
    "This section presents the **performance of multiple classification models** on the predictive maintenance dataset.  \n",
    "\n",
    "**Context:**  \n",
    "- The dataset is highly imbalanced (failures are rare).  \n",
    "- Multiple models were trained with preprocessing pipelines including **imputation, scaling, and one-hot encoding**.  \n",
    "- Metrics considered: **AUC**, **F1 (Macro)**, **Recall (Macro)**, **Precision (Macro)**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **1ï¸âƒ£ Key Takeaways from Metrics Table**\n",
    "\n",
    "| Model | AUC | F1 (Macro) | Recall (Macro) | Precision (Macro) |\n",
    "|-------|-----|------------|----------------|------------------|\n",
    "| XGBoost | 0.9781 | 0.872 | 0.882 | 0.862 |\n",
    "| LightGBM | 0.9778 | 0.841 | 0.875 | 0.813 |\n",
    "| GradientBoosting | 0.9774 | 0.855 | 0.798 | 0.942 |\n",
    "| CatBoost | 0.9766 | 0.850 | 0.862 | 0.839 |\n",
    "| RandomForest | 0.9670 | 0.772 | 0.705 | 0.918 |\n",
    "| ExtraTrees | 0.9579 | 0.723 | 0.652 | 0.958 |\n",
    "| AdaBoost | 0.9527 | 0.726 | 0.687 | 0.789 |\n",
    "| LogisticRegression | 0.8885 | 0.574 | 0.813 | 0.567 |\n",
    "\n",
    "**Insights:**  \n",
    "- **XGBoost, LightGBM, GradientBoosting, CatBoost** are the top-performing models.  \n",
    "- Logistic Regression performs the worst on **F1 and AUC**, likely due to the **class imbalance**.  \n",
    "- Ensemble methods (boosting) consistently outperform bagging methods (RandomForest, ExtraTrees) on AUC.\n",
    "\n",
    "---\n",
    "\n",
    "### **2ï¸âƒ£ ROC-AUC Curves**\n",
    "\n",
    "- The **ROC-AUC curve** visualizes the trade-off between **True Positive Rate** and **False Positive Rate** for each model.  \n",
    "- All top models achieve **AUC > 0.97**, indicating **excellent discrimination** between failures and normal cases.  \n",
    "- The diagonal line represents **random chance (AUC = 0.5)** for comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### **3ï¸âƒ£ Performance Metrics Comparison (Bar Charts)**\n",
    "\n",
    "- Bar charts provide a **visual comparison** of all models across **F1, Recall, and Precision**.  \n",
    "- Enables a quick identification of **high-precision vs high-recall models**, depending on business priorities:  \n",
    "  - For predictive maintenance, **Recall** might be prioritized to **catch as many failures as possible**, even at the cost of some false positives.  \n",
    "  - Precision is also important to **avoid unnecessary interventions**.  \n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Business Value:**  \n",
    "- These results guide **model selection** for deployment in predictive maintenance.  \n",
    "- Top models can be further tuned or used in **ensemble strategies** to maximize reliability.  \n",
    "- Visualizations (ROC + Bar Charts) provide **intuitive insights for stakeholders** beyond numeric metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44488f5b",
   "metadata": {},
   "source": [
    "### ðŸ”— Let's Connect\n",
    "\n",
    "[![LinkedIn](https://cdn-icons-png.flaticon.com/512/174/174857.png)](https://www.linkedin.com/in/ahmed-hamdy-4569a8360/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9da32",
   "metadata": {},
   "source": [
    "If you'd like to discuss projects or data science topics, connect on LinkedIn\n",
    "\n",
    "> If anybody would like to discuss any other projects or just have a chat about data science topics, I'll be more than happy to connect with you on LinkedIn: https:[/ahmed hamdy/](https://www.linkedin.com/in/ahmed-hamdy-4569a8360/)\n",
    "\n",
    "This notebook will always be a work in progress. Please leave any comments about further improvements to the notebook! Any feedback or constructive criticism is greatly appreciated. Thank you guys!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
